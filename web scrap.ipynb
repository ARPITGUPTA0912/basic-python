{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web scraping assignment\n",
      "\n",
      "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
      "\n",
      "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data\n",
      "is unstructured data in an HTML format which is then converted into structured data\n",
      "web scraping is used  for collecting data from websites\n",
      "-Data mining: It helps organizations collect and analyze information that can be useful for decision making,\n",
      "business intelligence or other purposes by extracting valuable insights from Website\n",
      "data sets such as social media platforms like Twitter, Facebook etc., customer feedback sites,\n",
      "ecommerce portals, blogs, news articles, research papers\n",
      "Monitoring e-commerce prices\n",
      "Finding opportunities for investment\n",
      "Analyzing social media web data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"web scraping assignment\\n\")\n",
    "q1='Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\\n'\n",
    "print(q1)\n",
    "ans1=\"\"\"Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data\n",
    "is unstructured data in an HTML format which is then converted into structured data\n",
    "web scraping is used  for collecting data from websites\n",
    "-Data mining: It helps organizations collect and analyze information that can be useful for decision making,\n",
    "business intelligence or other purposes by extracting valuable insights from Website\n",
    "data sets such as social media platforms like Twitter, Facebook etc., customer feedback sites,\n",
    "ecommerce portals, blogs, news articles, research papers\n",
    "Monitoring e-commerce prices\n",
    "Finding opportunities for investment\n",
    "Analyzing social media web data\n",
    "\"\"\"\n",
    "print(ans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2. What are the different methods used for Web Scraping?\n",
      "\n",
      "HTML Parsing\n",
      "A common script or template is typically used to encode data from the same category into similar pages. A wrapper\n",
      "is a program in data mining that detects such templates in a specific information source, extracts its content,\n",
      "and converts it to a relational form.\n",
      "Vertical Aggregation\n",
      "Several companies have created vertically specific harvesting platforms. These platforms generate and monitor\n",
      "a plethora of “bots” for specific verticals with no “man in the loop”\n"
     ]
    }
   ],
   "source": [
    "q2='Q2. What are the different methods used for Web Scraping?\\n'\n",
    "print(q2)\n",
    "ans2=\"\"\"HTML Parsing\n",
    "A common script or template is typically used to encode data from the same category into similar pages. A wrapper\n",
    "is a program in data mining that detects such templates in a specific information source, extracts its content,\n",
    "and converts it to a relational form.\n",
    "Vertical Aggregation\n",
    "Several companies have created vertically specific harvesting platforms. These platforms generate and monitor\n",
    "a plethora of “bots” for specific verticals with no “man in the loop”\"\"\"\n",
    "print(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3. What is Beautiful Soup? Why is it used?\n",
      "\n",
      "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup,\n",
      "i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to\n",
      "extract data from HTML,which is useful for web scraping.\n",
      "Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse\n",
      "tree.\n",
      "Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8.\n",
      "Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, which allows​ us to try out different\n",
      "parsing strategies or trade speed for flexibility.\n"
     ]
    }
   ],
   "source": [
    "q3=\"Q3. What is Beautiful Soup? Why is it used?\\n\"\n",
    "print(q3)\n",
    "ans3= \"\"\"Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup,\n",
    "i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to\n",
    "extract data from HTML,which is useful for web scraping.\n",
    "Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse\n",
    "tree.\n",
    "Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8.\n",
    "Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, which allows​ us to try out different\n",
    "parsing strategies or trade speed for flexibility.\"\"\"\n",
    "\n",
    "print(ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4. Why is flask used in this Web Scraping project?\n",
      "\n",
      "Flask is a web framework that allows developers to build lightweight web applications quickly and easily\n",
      "with Flask Libraries.\n",
      "flask is used to make web api  for web scraping web site.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4='Q4. Why is flask used in this Web Scraping project?\\n'\n",
    "print(q4)\n",
    "ans4=\"\"\"Flask is a web framework that allows developers to build lightweight web applications quickly and easily\n",
    "with Flask Libraries.\n",
    "flask is used to make web api  for web scraping web site.\n",
    "\"\"\"\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
      "\n",
      "aws is used to deploy project on there server with the git hub\n",
      "beanstack\n",
      "Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic\n",
      "Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, and auto scaling to\n",
      "application health monitoring.\n",
      "\n",
      "codepipeline\n",
      "AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps\n",
      "required to release your software. You can quickly model and configure the different stages of a software \n",
      "release process. CodePipeline automates the steps required to release your software changes continuously.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q5='Q5. Write the names of AWS services used in this project. Also, explain the use of each service.'\n",
    "print(q5)\n",
    "ans5=\"\"\"\n",
    "aws is used to deploy project on there server with the git hub\n",
    "beanstack\n",
    "Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic\n",
    "Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, and auto scaling to\n",
    "application health monitoring.\n",
    "\n",
    "codepipeline\n",
    "AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps\n",
    "required to release your software. You can quickly model and configure the different stages of a software \n",
    "release process. CodePipeline automates the steps required to release your software changes continuously.\n",
    "\"\"\"\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
